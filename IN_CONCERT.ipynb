{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IN CONCERT.ipynb",
      "provenance": [],
      "mount_file_id": "1Wr9SS6KG_kvQCHKeD6v95cpA59UdphJc",
      "authorship_tag": "ABX9TyMrMqWRxE7GKELCtzJtIfAZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iomichiamofede/iomichiamofede/blob/main/IN_CONCERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0U_xyzvW4tx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czcgZ2bDmJf3"
      },
      "source": [
        "# IN CONCERT structure determination\n",
        "\n",
        "This Colab notebook allows you to prepare analyze data for the INtegrated COevoultion Nmr Cryo-Em pRoTein structure determination method by [Napoli et. al](https://doi.org/). \n",
        "\n",
        "**Requirements**\n",
        "\n",
        "The method uses chemical shift assignments, distance and dihedral angle restraints from Nuclear Magnetic Resonance, an electron density map from cryo-electron microscopy and evolutionary couplings extracted from Multiple Sequence Alignements.\n",
        "\n",
        "The user should have access to CS-Rosetta and NAMDINATOR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HbDW8Q6nmaLX",
        "cellView": "form",
        "outputId": "f31b98be-8692-4709-f083-5129344979ee"
      },
      "source": [
        "#@title Import and install modules\n",
        "\n",
        "import pandas as pd\n",
        "import sys\n",
        "from io import StringIO\n",
        "import numpy as np\n",
        "!pip install prody\n",
        "import glob # Package for Unix-style pathname pattern expansion\n",
        "import os   # Python operating system interface"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: prody in /usr/local/lib/python3.7/dist-packages (2.0)\n",
            "Requirement already satisfied: biopython in /usr/local/lib/python3.7/dist-packages (from prody) (1.79)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from prody) (3.0.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from prody) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.10 in /usr/local/lib/python3.7/dist-packages (from prody) (1.19.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWDTEH7cvxaY",
        "cellView": "form",
        "outputId": "06e2513a-12e8-4d63-cf98-d3aba39110f4"
      },
      "source": [
        "#@title Mount drive\n",
        "\n",
        "#@markdown <font color='red'> **You have now access to your drive! Do not type anything riskful for your data (i.e. rm *)**\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "!pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6EliLrzpVMD"
      },
      "source": [
        "#@title Define functions\n",
        "\n",
        "#@markdown Please execute this cell by pressing the _Play_ button \n",
        "#@markdown on the left to define the functions that you will use\n",
        "#@markdown in this Colab notebook.\n",
        "\n",
        "#@markdown **Note**: Some functions are adapted from the CS-Rosetta\n",
        "#@markdown toolbox available [here](https://csrosetta.chemistry.ucsc.edu/downloads/toolbox).\n",
        "\n",
        "def cyana_2_atompair(lol,upl):\n",
        "\n",
        "    #### https://csrosetta.bmrb.io/format_help\n",
        "\n",
        "    #### AtomPair HB3  153 HA   153 BOUNDED 1.700 3.300 .500 NOE\n",
        "    #The first column should always be \"AtomPair\".\n",
        "    #The second column is the atom name of the first atom.\n",
        "    #The third column is the residue number of the first atom.\n",
        "    #The fourth column is the atom name of the second atom.\n",
        "    #The fifth column is the atom name of the second atom.\n",
        "    #The sixth column is the Rosetta function type. You can use any of the Rosetta functions, but the simplest to use is BOUNDED.\n",
        "    #The seventh column is the distance lower bound.\n",
        "    #The eighth column is the distance upper bound.\n",
        "    #The ninth column should always be .5\n",
        "    #The tenth column should always be NOE\n",
        "    print(\"Running...\")\n",
        "    # lol/upl file looks like this:\n",
        "    #   7 VAL QG2    185 ILE QD1    3.0 \n",
        "    colnameslol=['resnum1','resname1','atom1','resnum2','resname2','atom2','lol']\n",
        "    colnamesupl=['resnum1','resname1','atom1','resnum2','resname2','atom2','upl']\n",
        "    dflol = pd.read_csv(lol,delim_whitespace=True,names=colnameslol)\n",
        "    dfupl = pd.read_csv(upl,delim_whitespace=True,names=colnamesupl)\n",
        "    merged=pd.concat([dflol,dfupl['upl']],axis=1)\n",
        "\n",
        "    w=''\n",
        "    #### AtomPair HB3  153 HA   153 BOUNDED 1.700 3.300 .500 NOE\n",
        "    for index,row in merged.iterrows():\n",
        "      w+=('%s\\t%s\\t%s\\t%s\\t%s\\t%s\\t%s\\t%s\\t%s\\t%s\\n' % ('AtomPair',row['atom1'],row['resnum1'],row['atom2'],row['resnum2'],'BOUNDED',row['lol'],row['upl'],0.500,'NOE'))\n",
        "\n",
        "    out=open('AtomPair_%s.cst' % lol.split('.lol')[0],'w')\n",
        "    out.write(w)\n",
        "\n",
        "def renumber_and_trim_atompair(cst,offset,start,end):\n",
        "\n",
        "  colnames=['AtomPair','atom1','resnum1','atom2','resnum2','BOUNDED','lol','upl','0.500','NOE']\n",
        "  dfres=pd.read_csv(cst, header = None, delim_whitespace=True, names=colnames)\n",
        "\n",
        "  w=''\n",
        "  for index, row in dfres.iterrows():\n",
        "      if ((int(row['resnum1'])-offset)>start) and ((int(row['resnum2'])-offset)>start) and ((int(row['resnum1'])-offset)<end) and ((int(row['resnum2'])-offset)<end):\n",
        "          w += ('%s\\t%s\\t%s\\t%s\\t%s\\t%s\\t%s\\t%s\\t%s\\t%s\\n' % ('AtomPair',row['atom1'],int(row['resnum1'])-offset,row['atom2'],int(row['resnum2'])-offset,'BOUNDED',row['lol'],row['upl'],0.500,'NOE'))\n",
        "  out_ren=open(\"%s_ren_by_%s.cst\" % (cst.split('.cst')[0],offset),'w')   \n",
        "  out_ren.write(w)\n",
        "  out_ren.close()\n",
        "\n",
        "def DCA_2_cyana(DCA_file):\n",
        "\n",
        "  # This script converts a DCA .dat file into a cyana restraints.lol file\n",
        "  # It needs the .dat file\n",
        "  # .dat file looks like this:\n",
        "  #    13      26   |     A18     V32       1\n",
        "  #    282     341  |    H284    K343       2\n",
        "\n",
        "  # Output .lol looks like:\n",
        "  # 343\tLYS\tCB\t346\tGLU\tCB\t2.0\n",
        "  # 34\tILE\tCB\t38\tLYS\tCB\t2.0\n",
        "  print (\"Running...\")\n",
        "\n",
        "  \n",
        "\n",
        "  aa_table_one2three=\t{\n",
        "    \"A\" : \"ALA\",\n",
        "    \"C\" : \"CYS\",\n",
        "    \"D\" : \"ASP\",\n",
        "    \"E\" : \"GLU\",\n",
        "    \"F\" : \"PHE\",\n",
        "    \"G\" : \"GLY\",\n",
        "    \"H\" : \"HIS\",\n",
        "    \"I\" : \"ILE\",\n",
        "    \"K\" : \"LYS\",\n",
        "    \"L\" : \"LEU\",\n",
        "    \"M\" : \"MET\",\n",
        "    \"N\" : \"ASN\",\n",
        "    \"P\" : \"PRO\",\n",
        "    \"Q\" : \"GLN\",\n",
        "    \"R\" : \"ARG\",\n",
        "    \"S\" : \"SER\",\n",
        "    \"T\" : \"THR\",\n",
        "    \"V\" : \"VAL\",\n",
        "    \"W\" : \"TRP\",\n",
        "    \"Y\" : \"TYR\"}\n",
        "\n",
        "  # Read the input file\n",
        "  dfprot = pd.read_csv(DCA_file,delim_whitespace=True,header = None)\n",
        "\n",
        "  w=''\n",
        "  v=''\n",
        "  for index, row in dfprot.iterrows():\n",
        "      res1nam=aa_table_one2three[row[3][0]]\n",
        "      res1num=row[3][1:]\n",
        "      res2nam=aa_table_one2three[row[4][0]]\n",
        "      res2num=row[4][1:]\n",
        "      atom1='CB'\n",
        "      atom2='CB'\n",
        "      if res1nam=='GLY': \n",
        "          atom1='CA'\n",
        "      if res2nam=='GLY': \n",
        "          atom2='CA'  \n",
        "      w+= (\"%s\\t%s\\t%s\\t%s\\t%s\\t%s\\t%1.1f\\n\" % (res1num,res1nam,atom1,res2num,res2nam,atom2,2.0))\n",
        "      v+= (\"%s\\t%s\\t%s\\t%s\\t%s\\t%s\\t%1.1f\\n\" % (res1num,res1nam,atom1,res2num,res2nam,atom2,7.0))\n",
        "\n",
        "  outL=open('Unfiltered_%s.lol' % DCA_file.split('.dat')[0],'w')\n",
        "  outU=open('Unfiltered_%s.upl' % DCA_file.split('.dat')[0],'w')\n",
        "  outL.write(w)\n",
        "  outU.write(v)\n",
        "\n",
        "def Network_Anchoring(coev_file,NMR_file):\n",
        "\n",
        "  ######################################\n",
        "  # Parameters to be tweaked: (could be made as input parameters rather than hard-coded here!)\n",
        "  upl=7.0 # The distance limit that will be written in the output file\n",
        "  seqtolerance = 4 # it will search for contacts around the given residue plus/minus this number\n",
        "\n",
        "  class restraint:\n",
        "    def __init__(self, res1, aa1,atom1,res2, aa2,atom2,source):\n",
        "      if res1<res2:\n",
        "          self.res1 = res1\n",
        "          self.res2 = res2\n",
        "          self.aa1 = aa1\n",
        "          self.aa2 = aa2\n",
        "          self.atom1 = atom1\n",
        "          self.atom2 = atom2\n",
        "      else:\n",
        "          self.res1 = res2\n",
        "          self.res2 = res1\n",
        "          self.aa1 = aa2\n",
        "          self.aa2 = aa1\n",
        "          self.atom1 = atom2\n",
        "          self.atom2 = atom1\n",
        "\n",
        "      self.source = source\n",
        "\n",
        "  columnnames=['res1','aa1','atom1','res2','aa2','atom2','dist']\n",
        "\n",
        "  restraintlist1=[] # This will collect all the restraints from the first set of files (e.g. coevolution)\n",
        "  restraintlist2=[] # This will collect all the restraints from the second set of files (e.g. NMR)\n",
        "\n",
        "  a=pd.read_csv(coev_file,delim_whitespace=True,header=None,names=columnnames)\n",
        "  source = coev_file\n",
        "  for index, row in a.iterrows():\n",
        "          restraintlist1.append(restraint(row['res1'],row['aa1'],row['atom1'],row['res2'],row['aa2'],row['atom2'],source))\n",
        "\n",
        "  b=pd.read_csv(NMR_file,delim_whitespace=True,header=None,names=columnnames)\n",
        "  source = NMR_file\n",
        "  for index, row in b.iterrows():\n",
        "      restraintlist2.append(restraint(row['res1'],row['aa1'],row['atom1'],row['res2'],row['aa2'],row['atom2'],source))\n",
        "\n",
        "\n",
        "  outscore0=open('Discarded_%s.upl' % (coev_file.split('.lol')[0]).split('Unfiltered_')[1],'w')\n",
        "  outscore1=open('Filtered_%s.upl' % (coev_file.split('.lol')[0]).split('Unfiltered_')[1],'w')\n",
        "  outscore1L=open('Filtered_%s.lol' % (coev_file.split('.lol')[0]).split('Unfiltered_')[1],'w')\n",
        "  outdetails=open('Network_Ancoring_details_%s' % (coev_file.split('.lol')[0]).split('Unfiltered_')[1],'w')\n",
        "\n",
        "  restraintsdata1=[]\n",
        "  restraintsdata2=[]\n",
        "\n",
        "  for q in range(len(restraintlist1)):\n",
        "      restraintsdata1.append([restraintlist1[q].res1,restraintlist1[q].aa1,restraintlist1[q].atom1,restraintlist1[q].res2,restraintlist1[q].aa2,restraintlist1[q].atom2,restraintlist1[q].source])\n",
        "      \n",
        "  for p in range(len(restraintlist2)):\n",
        "      restraintsdata2.append([restraintlist2[p].res1,restraintlist2[p].aa1,restraintlist2[p].atom1,restraintlist2[p].res2,restraintlist2[p].aa2,restraintlist2[p].atom2,restraintlist2[p].source])\n",
        "      \n",
        "  df_restraints1=pd.DataFrame.drop_duplicates(pd.DataFrame(restraintsdata1,columns=['res1','aa1','atom1','res2','aa2','atom2','source'])) # Add more columns here    \n",
        "  df_restraints2=pd.DataFrame.drop_duplicates(pd.DataFrame(restraintsdata2,columns=['res1','aa1','atom1','res2','aa2','atom2','source'])) # Add more columns here\n",
        "  data3=[]\n",
        "  data2=[]\n",
        "  data1=[]\n",
        "  data0=[]\n",
        "  ############################\n",
        "  # Now go through all the restraints in list 1 and check if they are there in list 2\n",
        "\n",
        "  for index, row in df_restraints1.iterrows():\n",
        "      testtuplelist=[]\n",
        "      currentrestraint=(row['res1'],row['res2'])\n",
        "      for tol1 in np.arange(-seqtolerance,seqtolerance+1): # allow the search within some tolerance on residue 1\n",
        "          for tol2 in np.arange(-seqtolerance,seqtolerance+1): # allow the search within some tolerance on residue 2\n",
        "              testtuplelist.append((row['res1']+tol1,row['res2']+tol2))\n",
        "      testflag=0\n",
        "      supportingrestraints=[]\n",
        "      #supportingrestraints_full=[]\n",
        "      outdetails.write(\"\\n\") # This is just to have separation lines in the details file; decoration.\n",
        "      for k, line in df_restraints2.iterrows():\n",
        "          reftuple=(line['res1'],line['res2'])\n",
        "          if reftuple in testtuplelist:\n",
        "              testflag+=1\n",
        "              supportingrestraints.append(reftuple)\n",
        "              outdetails.write(\"Search restraint %s\\t%s\\t%s\\t%s\\t%s\\t%s\\tfrom\\t%s\\t Found restraint %s\\t%s\\t%s\\t%s\\t%s\\t%s\\tin\\t%s\\n\" % (row['res1'],row['aa1'],row['atom1'],row['res2'],row['aa2'],row['atom2'],row['source'],line['res1'],line['aa1'],line['atom1'],line['res2'],line['aa2'],line['atom2'],line['source']))\n",
        "\n",
        "      if testflag>0:  # found one or more matches\n",
        "  #\t\toutscore1.write(\"%s\\t%s\\t%s\\t%s\\t%s\\t%s\\t%s\\n\" % (restraintlist1[i].res1,restraintlist1[i].aa1,restraintlist1[i].atom1,restraintlist1[i].res2,restraintlist1[i].aa2,restraintlist1[i].atom2,upl))\n",
        "          data1.append([row['res1'],row['aa1'],row['atom1'],row['res2'],row['aa2'],row['atom2'],upl])\n",
        "\n",
        "      else: # constraint not supported\n",
        "  #\t\toutscore0.write(\"%s\\t%s\\t%s\\t%s\\t%s\\t%s\\t%s\\n\" % (restraintlist1[i].res1,restraintlist1[i].aa1,restraintlist1[i].atom1,restraintlist1[i].res2,restraintlist1[i].aa2,restraintlist1[i].atom2,upl))\n",
        "          data0.append([row['res1'],row['aa1'],row['atom1'],row['res2'],row['aa2'],row['atom2'],upl])\n",
        "\n",
        "  columnsfinal=['res1','aa1','atom1','res2','aa2','atom2','upl']\n",
        "  df1=pd.DataFrame.drop_duplicates(pd.DataFrame(data1, columns=columnsfinal))\n",
        "  df0=pd.DataFrame.drop_duplicates(pd.DataFrame(data0, columns=columnsfinal))\n",
        "\n",
        "  for index, row in df1.iterrows():\n",
        "      outscore1.write(\"%s\\t%s\\t%s\\t%s\\t%s\\t%s\\t%s\\n\" % (row['res1'],row['aa1'],row['atom1'],row['res2'],row['aa2'],row['atom2'],row['upl']))\n",
        "      outscore1L.write(\"%s\\t%s\\t%s\\t%s\\t%s\\t%s\\t%s\\n\" % (row['res1'],row['aa1'],row['atom1'],row['res2'],row['aa2'],row['atom2'],2.0))\n",
        "  for index, row in df0.iterrows():\n",
        "      outscore0.write(\"%s\\t%s\\t%s\\t%s\\t%s\\t%s\\t%s\\n\" % (row['res1'],row['aa1'],row['atom1'],row['res2'],row['aa2'],row['atom2'],row['upl']))\n",
        "\n",
        "\n",
        "  outscore1.close()\n",
        "  outscore1L.close()\n",
        "  outscore0.close()\n",
        "  outdetails.close()\n",
        "\n",
        "def CEYAPP_2_cyana(CEYAPP_file):\n",
        "  \n",
        "  # This function converts a contacts.txt (CE-YAPP) format into 2 cyana format constraints files (.lol [2 A] + .upl [7 A])  \n",
        "  # It needs the .txt file\n",
        "  # txt file looks like this:\n",
        "  # 343 LYS CB 346 GLU CB    1.00\n",
        "  # 34 ILE CB 38 LYS CB      1.00\n",
        "  # Output .lol looks like:\n",
        "  #  7   VAL     QG2       185  ILE QD1    3.0 \n",
        "  #  15  VAL     QG2       16   VAL QG2    3.0 \n",
        "  # Output .upl looks like:\n",
        "  #  7   VAL     QG2       185  ILE QD1    15.0 \n",
        "  #  15  VAL     QG2       16   VAL QG2    15.0 \n",
        "\n",
        "  print( \"Running...\")\n",
        "\n",
        " # A dictionary for the conversion of atom names\n",
        "  atom_table=\t{\n",
        "    \"HA\" : \"QA\",\n",
        "    \"HB\" : \"QB\",\n",
        "    \"HG\" : \"QG\",\n",
        "    \"HD\" : \"QD\",\n",
        "    \"HG1\" : \"QG1\",\n",
        "    \"HG2\" : \"QG2\",\n",
        "    \"HD1\" : \"QD1\",\n",
        "    \"HD2\" : \"QD2\",\n",
        "    \"CA\" : \"CA\",\n",
        "    \"CB\" : \"CB\",\n",
        "    \"CG\" : \"CG\",\n",
        "    \"CD\" : \"CD\",\n",
        "    \"CG1\" : \"CG1\",\n",
        "    \"CG2\" : \"CG2\",\n",
        "    \"CD1\" : \"CD1\",\n",
        "    \"CD2\" : \"CD2\",\n",
        "      \"N\" : \"N\"}\n",
        "\n",
        "  conts=CEYAPP_file\n",
        " \n",
        "  # Read the input file\n",
        "  dfprot = pd.read_csv(conts,delim_whitespace=True,header = None)\n",
        "\n",
        "  w=''\n",
        "  for index, row in dfprot.iterrows():\n",
        "    w+= (\"%s\\t%s\\t%s\\t%s\\t%s\\t%s\\t%1.1f\\n\" % (row[0],row[1], atom_table[row[2]],row[3],row[4], atom_table[row[5]],2.0))\n",
        "  out=open('Unfiltered_%s.lol' % conts.split('.txt')[0],'w')\n",
        "  out.write(w)\n",
        "\n",
        "  w=''\n",
        "  out=''\n",
        "  for index, row in dfprot.iterrows():\n",
        "    w+= (\"%s\\t%s\\t%s\\t%s\\t%s\\t%s\\t%1.1f\\n\" % (row[0],row[1], atom_table[row[2]],row[3],row[4], atom_table[row[5]],7.0))\n",
        "\n",
        "  out=open('Unfiltered_%s.upl' % conts.split('.txt')[0],'w')\n",
        "  out.write(w)\n",
        "\n",
        "def GREMLIN_2_cyana(GREMLIN_file):\n",
        "  # This script converts a GREMLIN file into a cyana restraints.lol file\n",
        "  # It needs the GREMLIN file\n",
        "  # GREMLIN file looks like this:\n",
        "  #K 343\tE 346\t4.338\t1.00\t3.30\n",
        "\n",
        "  # Output .lol looks like:\n",
        "  # 343\tLYS\tCB\t346\tGLU\tCB\t2.0\n",
        "  # 34\tILE\tCB\t38\tLYS\tCB\t2.0\n",
        "\n",
        "  print (\"Running...\")\n",
        "\n",
        "  aa_table_one2three=\t{\n",
        "    \"A\" : \"ALA\",\n",
        "    \"C\" : \"CYS\",\n",
        "    \"D\" : \"ASP\",\n",
        "    \"E\" : \"GLU\",\n",
        "    \"F\" : \"PHE\",\n",
        "    \"G\" : \"GLY\",\n",
        "    \"H\" : \"HIS\",\n",
        "    \"I\" : \"ILE\",\n",
        "    \"K\" : \"LYS\",\n",
        "    \"L\" : \"LEU\",\n",
        "    \"M\" : \"MET\",\n",
        "    \"N\" : \"ASN\",\n",
        "    \"P\" : \"PRO\",\n",
        "    \"Q\" : \"GLN\",\n",
        "    \"R\" : \"ARG\",\n",
        "    \"S\" : \"SER\",\n",
        "    \"T\" : \"THR\",\n",
        "    \"V\" : \"VAL\",\n",
        "    \"W\" : \"TRP\",\n",
        "    \"Y\" : \"TYR\"}\n",
        "\n",
        "  dat=GREMLIN_file\n",
        "  # Read the input file\n",
        "  dfprot = pd.read_csv(dat,delim_whitespace=True,header = None)\n",
        "\n",
        "  w=''\n",
        "  v=''\n",
        "  for index, row in dfprot.iterrows():\n",
        "      res1nam=aa_table_one2three[row[0]] \n",
        "      res1num=row[1]\n",
        "      res2nam=aa_table_one2three[row[2]]\n",
        "      res2num=row[3]\n",
        "      atom1='CB'\n",
        "      atom2='CB'\n",
        "      if res1nam=='GLY': \n",
        "          atom1='CA'\n",
        "      if res2nam=='GLY': \n",
        "          atom2='CA'  \n",
        "      w+= (\"%s\\t%s\\t%s\\t%s\\t%s\\t%s\\t%1.1f\\n\" % (res1num,res1nam,atom1,res2num,res2nam,atom2,2.0))\n",
        "      v+= (\"%s\\t%s\\t%s\\t%s\\t%s\\t%s\\t%1.1f\\n\" % (res1num,res1nam,atom1,res2num,res2nam,atom2,7.0))\n",
        "\n",
        "  outL=open('Unfiltered_%s.lol' % dat.split('.dat')[0],'w')\n",
        "  outU=open('Unfiltered_%s.upl' % dat.split('.dat')[0],'w')\n",
        "  outL.write(w)\n",
        "  outU.write(v)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCw6pPnPt4iR",
        "outputId": "bc4877e7-a719-44f5-e2d4-046eee73534f"
      },
      "source": [
        "#@markdown ---\n",
        "#@markdown ### <font color='yellow'> 📁 Enter your files path: \n",
        "file_path = \"drive/MyDrive/IN_CONCERT\" #@param {type:\"string\"}\n",
        "%cd $file_path\n",
        "#@markdown ### <font color='yellow'> Enter your files names:\n",
        "NMRlow='NMR.lol' #@param {type:\"string\"}\n",
        "NMRup='NMR.upl' #@param {type:\"string\"}\n",
        "COEV_file='GREMLIN_contacts.dat' #@param {type:\"string\"}\n",
        "#@markdown ### <font color='yellow'> Enter your CoEvolution data type:\n",
        "CoEvolution_Type = 'GREMLIN' #@param [\"DCA\", \"GREMLIN\", \"CEYAPP\"]\n",
        "#@markdown ---"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/IN_CONCERT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J0XQkLnA1YWt",
        "outputId": "ac7ab55c-47b7-4916-d58c-830530c834ac"
      },
      "source": [
        "#@title Network Anchoring\n",
        "if(CoEvolution_Type==\"DCA\"):\n",
        "  DCA_2_cyana(COEV_file)\n",
        "  COEV_unfiltered_low='Unfiltered_%s.lol' % COEV_file.split('.dat')[0]\n",
        "  COEV_unfiltered_up='Unfiltered_%s.upl' % COEV_file.split('.dat')[0]\n",
        "  Network_Anchoring(COEV_unfiltered_low,NMRlow)\n",
        "  COEV_filtered_low='Filtered_%s.lol' % COEV_file.split('.dat')[0]\n",
        "  COEV_filtered_up='Filtered_%s.upl' % COEV_file.split('.dat')[0]\n",
        "elif(CoEvolution_Type==\"GREMLIN\"):\n",
        "  GREMLIN_2_cyana(COEV_file)\n",
        "  COEV_unfiltered_low='Unfiltered_%s.lol' % COEV_file.split('.dat')[0]\n",
        "  COEV_unfiltered_up='Unfiltered_%s.upl' % COEV_file.split('.dat')[0]\n",
        "  Network_Anchoring(COEV_unfiltered_low,NMRlow)\n",
        "  COEV_filtered_low='Filtered_%s.lol' % COEV_file.split('.dat')[0]\n",
        "  COEV_filtered_up='Filtered_%s.upl' % COEV_file.split('.dat')[0]\n",
        "else:\n",
        "  CEYAPP_2_cyana(COEV_file)\n",
        "  COEV_unfiltered_low='Unfiltered_%s.lol' % COEV_file.split('.txt')[0]\n",
        "  COEV_unfiltered_up='Unfiltered_%s.upl' % COEV_file.split('.txt')[0]\n",
        "  Network_Anchoring(COEV_unfiltered_low,NMRlow)\n",
        "  COEV_filtered_low='Filtered_%s.lol' % COEV_file.split('.txt')[0]\n",
        "  COEV_filtered_up='Filtered_%s.upl' % COEV_file.split('.txt')[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPN-gtp3y3zP",
        "cellView": "form",
        "outputId": "2a14c76f-bc51-4c24-db51-8404f16d2df2"
      },
      "source": [
        "#@title Convert restraints to Rosetta format\n",
        "cyana_2_atompair(NMRlow,NMRup)\n",
        "NMRcst=('AtomPair_%s.cst' % NMRlow.split('.lol')[0])\n",
        "cyana_2_atompair(COEV_filtered_low,COEV_filtered_up)\n",
        "COEVcst=('AtomPair_%s.cst' % COEV_filtered_low.split('.lol')[0])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running...\n",
            "Running...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "euupK1TNPivF"
      },
      "source": [
        "#@title Renumber and trim\n",
        "#@markdown ### <font color='yellow'> Enter your settings:\n",
        "start_position = 5 #@param {type:\"integer\"}\n",
        "end_position = 335 #@param {type:\"integer\"}\n",
        "offset = 12 #@param {type:\"slider\", min:-50, max:50, step:1}\n",
        "renumber_and_trim_atompair(NMRcst,offset,start_position,end_position)\n",
        "renumber_and_trim_atompair(COEVcst,offset,start_position,end_position)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}